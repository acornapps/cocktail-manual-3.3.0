---
title: "7.5.1 报警目录"
excerpt: ""
permalink: /docs/zh/7.5.1/
redirect_from:
  - /theme-setup/
toc: false
toc_sticky: false
sidebar:
  nav: "zh"
---

---
在以下目录的持续时间内，触发条件仍未改善时报警。

* 报警管理

| 报警 ID | **ALM-001** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | AlertmanagerDown |
| 持续时间 | 5分钟 |
| 触发条件 | 无法搜集报警管理度量时启动 |
| 解决方案 | 检查 Prometheus 日志以及报警管理日志和事件。必要时重启 Pod。 |

| 报警 ID | **ALM-002** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | AlertmanagerFailedReload |
| 持续时间 | 10分钟 |
| 触发条件 | 修改管理设置时，重读设置失败时启动 |
| 解决方案 | 检查该 Pod 日志，纠正配置图设置错误。 |

* ETCD3

| 报警 ID | **ETC-001** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | InsufficientMembers |
| 持续时间 | 3分钟 |
| 触发条件 | 无法搜集 ETCD 度量时启动 |
| 解决方案 | 检查 ETCD 集群状态。检查 Prometheus 日志和该节点的 etcd 状态。|

| 报警 ID | **ETC-002** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | NoLeader |
| 持续时间 | 1分钟 |
| 触发条件 | 没有 ETCD leader 时启动 |
| 解决方案 | 检查 ETCD 集群状态。可能是磁盘延迟引起的问题，对 ETCD 集群的所有节 点执行以下命令。 \([ETCD Tuning](https://coreos.com/etcd/docs/latest/tuning.html#disk)\)<br /> ``$ sudo ionice -c2 -n0 -p `pgrep etcd` `` |

| 报警 ID | **ETC-003** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | HighNumberOfLeaderChanges |
| 持续时间 | 即时 |
| 触发条件 | 最近 1 小时内 Leader 修改 3 次以上时 |
| 解决方案 | 检查 ETCD 集群状态。可能是磁盘延迟引起的问题，对 ETCD 集群的所有节 点执行以下命令。 \([ETCD Tuning](https://coreos.com/etcd/docs/latest/tuning.html#disk)\)<br /> ``$ sudo ionice -c2 -n0 -p `pgrep etcd` `` |

| 报警 ID | **ETC-004** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | HighNumberOfFailedGRPCRequests |
| 持续时间 | 10分钟 |
| 触发条件 | 最近 5 分钟内 gRPC 方法导出失败达到 1%以上时 |
| 解决方案 | 需要增加 ETCD 集群和 Kubernetes 集群带宽，或者按比例增加集群。 |

| 报警 ID | **ETC-005** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | HighNumberOfFailedGRPCRequests |
| 持续时间 | 5分钟 |
| 触发条件 | 最近 5 分钟内 gRPC 方法导出失败达到 5%以上时 |
| 解决方案 | 需要增加 ETCD 集群和 Kubernetes 集群带宽，或者按比例增加集群。 |

| 报警 ID | **ETC-006** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | GRPCRequestsSlow |
| 持续时间 | 10分钟 |
| 触发条件 | 最近 5 分钟内 gRPC 方法请求等待时间第 99 位百分位大于 150ms 时 |
| 解决方案 | 需要增加 ETCD 集群和 Kubernetes 集群带宽，或者按比例增加集群。 |

| 报警 ID | **ETC-007** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | HighNumberOfFailedHTTPRequests |
| 持续时间 | 10分钟 |
| 触发条件 | 最近 5 分钟内 HTTP end point 请求失败达到 1%以上时 |
| 解决方案 | 需要增加 ETCD 集群和 Kubernetes 集群带宽，或者按比例增加集群。 |

| 报警 ID | **ETC-008** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | HighNumberOfFailedHTTPRequests |
| 持续时间 | 5分钟 |
| 触发条件 | 最近 5 分钟内 HTTP end point 请求失败达到 5%以上时 |
| 解决方案 | 需要增加 ETCD 集群和 Kubernetes 集群带宽，或者按比例增加集群。 |

| 报警 ID | **ETC-009** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | HTTPRequestsSlow |
| 持续时间 | 10分钟 |
| 触发条件 | 最近 5 分钟内 HTTP 请求等待时间第 99 位百分位大于 150ms 时 |
| 解决方案 | 需要增加 ETCD 集群和 Kubernetes 集群带宽，或者按比例增加集群。 |

| 报警 ID | **ETC-010** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | EtcdMemberCommunicationSlow |
| 持续时间 | 10分钟 |
| 触发条件 | 最近 5 分钟内会员之间通信等待时间第 99 位百分位大于 150ms 时 |
| 解决方案 | 需要增加 ETCD 集群带宽，或者按比例增加集群。 |

| 报警 ID | **ETC-011** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | HighNumberOfFailedProposals |
| 持续时间 | 即时 |
| 触发条件 | 最近 1 小时内 raft 协议请求失败达到 5 个以上时<br /> \(RAFT 协议是 ETCD 同步协议\) |
| 解决方案 | 据[ETCD metric 文件](https://github.com/coreos/etcd/blob/master/Documentation/metrics.md/)，Leader 选举暂时失败或者会员人数不足，导致 ETCD 集 群中断时间延长时启动。<br /> 检查有无 Leader 以及被中断的 ETCD 会员。 |

| 报警 ID | **ETC-012** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | HighFsyncDurations |
| 持续时间 | 10分钟 |
| 触发条件 | 最近 5 分钟内 Wal fsync 持续时间第 99 位百分位大于 500ms 时<br /> \(Wal fsync:适用日志项之前，保存于磁盘时导出\) |
| 解决方案 | 据[ETCD metric 文件](https://github.com/coreos/etcd/blob/master/Documentation/metrics.md/)文件，磁盘出现问题时启动。 |

| 报警 ID | **ETC-013** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | HighCommitDurations |
| 持续时间 | 10 分钟 |
| 触发条件 | 最近 5 分钟内承诺持续时间第 99 位百分位大于 250ms 时<br /> \(backend commit: 近期修改磁盘内容的增量快照承诺.\) |
| 解决方案 | 据[ETCD metric 文件](https://github.com/coreos/etcd/blob/master/Documentation/metrics.md/)磁盘出现问题时启动。 |

* General

| 报警 ID | **GEN-001** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | TargetDown |
| 持续时间 | 10 分钟 |
| 触发条件 | 无法搜集度量时启动。显示哪些操作失败。 |
| 解决方案 | 检查 Prometheus 日志以及相应作业的 Pod 日志及事件。 |

| 报警 ID | **GEN-002** |
| :--- | :--- |
| 重要程度 | ~~none~~ |
| 报警名称 | DeadMansSwitch |
| 持续时间 | 即时 |
| 触发条件 | DeadMansSwitch 通知。 |
| 解决方案 | 该报警不通知用户。|

| 报警 ID | **GEN-003** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | TooManyOpenFileDescriptors |
| 持续时间 | 10 分钟 |
| 触发条件 | 文件描述符的使用率超过 95%时启动 |
| 解决方案 | 修改节点限值。(需要重启节点) |

| 报警 ID | **GEN-004** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | FdExhaustionClose |
| 持续时间 | 10 分钟 |
| 触发条件 | 通过简单直线回归，预测 4 小时内将发生文件描述符枯竭时启动 |
| 解决方案 | 检查该 Pod 日志及事件。必要时修改节点限值。(需要重启节点) |

| 报警 ID | **GEN-005** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | FdExhaustionClose |
| 持续时间 | 10 分钟 |
| 触发条件 | 通过简单直线回归，预测 1 小时内将发生文件描述符枯竭时启动 |
| 解决方案 | 检查该 Pod 日志及事件。 必要时修改节点限值。(需要重启节点) |

*  Kube-ApiServer

| 报警 ID | **KAS-001** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | K8SApiserverDown |
| 持续时间 | 5 分钟|
| 触发条件 | 无法搜集 Kube-apiserver 度量时启动 |
| 解决方案 | 检查 Prometheus 日志、kube-apiserver 的日志和事件。 必要时重启 Pod。 |

| 报警 ID | **KAS-002** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | K8SApiServerLatency |
| 持续时间 | 10 分钟 |
| 触发条件 | 最近 10 分钟内请求等待时间第 99 位百分位大于 1s 时启动 |
| 解决方案 | 仍未改善时，添加主节点。 |

*  Kube-ControllerManager

| 报警 ID | **KCM-001** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | K8SControllerManagerDown |
| 持续时间 | 5 分钟|
| 触发条件 | 无法搜集 Kube-controller-manager 度量时启动 |
| 解决方案 | 检查 Prometheus 日志、kube-controller-manager 的日志及事件。 必要时重启 Pod。|

*  Kube-Scheduler

| 报警 ID | **KSC-001** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | K8SSchedulerDown |
| 持续时间 | 5 分钟|
| 触发条件 | 无法搜集 Kube-scheduler 度量时启动 |
| 解决方案 | 检查 Prometheus 日志、kube-scheduler 的日志及事件。 必要时重启 Pod。 |

*  Kube-State-Metrics

| 报警 ID | **KSM-001** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | DeploymentGenerationMismatch |
| 持续时间 | 15 分钟|
| 触发条件 | 部署所设置的 generation 和所搜集的 generation 不一致时启动 |
| 解决方案 | 检查部署日志及事件。 必要时重新部署 Deployment。 |

| 报警 ID | **KSM-002** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | DeploymentReplicasNotUpdated |
| 持续时间 | 15 分钟|
| 触发条件 | 部署所设置的拷贝数量被修改，或者可利用状态的拷贝数量不一致时启动 |
| 解决方案 | 因部署修改内容未上报状态导致，检查部署、Pod 日志及事件。 |

| 报警 ID | **KSM-003** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | DaemonSetRolloutStuck |
| 持续时间 | 15 分钟|
| 触发条件 | DaemonSet 中有非就绪状态 Pod 时启动 |
| 解决方案 | 检查该 Daemonset、Pod 日志及事件。 |

| 报警 ID | **KSM-004** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | K8SDaemonSetsNotScheduled |
| 持续时间 | 10 分钟 |
| 触发条件 | DaemonSet 上需要运行的 Pod 数量少于正在运行的 Pod 数量时启动 |
| 解决方案 | 检查该 Daemonset、Pod 日志及事件。<br /> 检查未经部署的节点是否正常。<br /> 主节点被隔离的，检查 Daemonset 是否设置了容忍值。 |

| 报警 ID | **KSM-005** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | DaemonSetsMissScheduled |
| 持续时间 | 10 分钟 |
| 触发条件 | DaemonSet 错误排列 Pod 时启动 |
| 解决方案 | 检查该 Daemonset、Pod 日志及事件。 |

| 报警 ID | **KSM-006** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | PodFrequentlyRestarting |
| 持续时间 | 10 分钟 |
| 触发条件 | 最近 1 小时内 Pod 重启次数超过 5 次时启动 |
| 解决方案 | 检查该 Pod 日志及事件。必要时重启 Pod。 |

*  Kubelet

| 报警 ID | **KBL-001** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | K8SNodeNotReady |
| 持续时间 | 1 小时 |
| 触发条件 | 节点状态为非就绪时启动 |
| 解决方案 | 检查该节点状态及事件。通过 ssh 访问节点，检查 kubelet 状态。 |

| 报警 ID | **KBL-002** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | K8SManyNodesNotReady |
| 持续时间 | 1분 |
| 触发条件 | 所有集群中节点状态为非就绪的比例超过 20%时启动 |
| 解决方案 | 检查该节点状态及事件。<br /> 通过 ssh 访问节点，检查 kubelet 状态。|

| 报警 ID | **KBL-003** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | K8SKubeletDown |
| 持续时间 | 1 小时 |
| 触发条件 | 所有集群中 kubelet metric 搜集失败比例超过 3%时启动 |
| 解决方案 | 检查 Prometheus 日志、该节点状态及事件。<br /> 通过 ssh 访问节点，检查 kubelet 状态。|

| 报警 ID | **KBL-004** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | K8SKubeletDown |
| 持续时间 | 1 小时 |
| 触发条件 | 所有集群中 kubelet metric 搜集失败比例超过 10%时启动 |
| 解决方案 | 检查 Prometheus 日志、该节点状态及事件。<br /> 通过 ssh 访问节点，检查 kubelet 状态。 |

| 报警 ID | **KBL-005** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | K8SKubeletTooManyPods |
| 持续时间 | 即时 |
| 触发条件 | 节点已部署 Pod 数量超过 100 个时启动(限值为 110) |
| 解决方案 | 达到限值时，不再创建 Pod。<br /> 同样检查其他节点状态，如没有富余增加节点。 |

*  节点

| 报警 ID | **NOD-001** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | NodeExporterDown |
| 持续时间 | 10 分钟 |
| 触发条件 | 无法搜集节点导出度量时启动 |
| 解决方案 | 检查 Prometheus 日志、节点导出日志及事件。<br /> 必要时重启 Pod。|

| 报警 ID | **NOD-002** |
| :--- | :--- |
| 重要程度 | **危急** |
| 报警名称 | K8SNodeOutOfDisk |
| 持续时间 | 即时 |
| 触发条件 | 节点状态为 OutOfDisk 时启动 |
| 解决方案 | 增加该节点的磁盘。 |

| 报警 ID | **NOD-003** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | K8SNodeMemoryPressure |
| 持续时间 | 即时 |
| 触发条件 | 节点状态为内存压力时启动 |
| 解决方案 | 增加该节点的内存。 |

| 报警 ID | **NOD-004** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | K8SNodeDiskPressure |
| 持续时间 | 即时 |
| 触发条件 | 节点状态为磁盘压力时启动 |
| 解决方案 | 删除节点的日志、未使用 dodkcer 映像、pv 备份等，确保磁盘空间。<br /> 仍未改善时，增加该节点的磁盘。 |

| 报警 ID | **NOD-005** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | NodeCPUUsage |
| 持续时间 | 30 分钟 |
| 触发条件 | 节点的最近 5 分钟内平均 CPU 使用量超过 90%时启动 |
| 解决方案 | 增加该节点的 CPU。 |

| 报警 ID | **NOD-006** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | NodeMemoryUsage |
| 持续时间 | 30 分钟 |
| 触发条件 | 节点内存使用量超过 90%时启动 |
| 解决方案 | 增加该节点的内存。 |

*  Prometheus

| 报警 ID | **PRM-001** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | PrometheusFailedReload |
| 持续时间 | 10 分钟 |
| 触发条件 | 修改 Prometheus 设置时，设置重读操作失败则启动 |
| 解决方案 | 检查该 Pod 日志，纠正配置图的设置错误。 |

*  System

| 报警 ID | **CKT-001** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | PvLowRequestDisk |
| 持续时间 | 30 分钟 |
| 触发条件 | 相比 PV 请求的磁盘大小，其使用量超过 80%时启动 |
| 解决方案 | 增加 PV 值。但，需要重新部署服务器。 |

| 报警 ID | **CKT-002** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | PvLowTotalDisk |
| 持续时间 | 30 分钟 |
| 触发条件 | 相比已挂载 PV 的磁盘大小，其使用量超过 80%时启动 |
| 解决方案 | 检查已挂载磁盘状态，删除未使用的 PV。<br /> 必要时增加磁盘。 |

| 报警 ID | **CKT-003** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | PodCPULimitUsage |
| 持续时间 | 30 分钟 |
| 触发条件 | 相比资源设定限值，CPU 使用量超过 90%时启动 |
| 解决方案 | 仍未改善时，修改 Deployment 的 CPU 限值 |

| 报警 ID | **CKT-004** |
| :--- | :--- |
| 重要程度 | 警告 |
| 报警名称 | PodMemoryLimitUsage |
| 持续时间 | 30 分钟 |
| 触发条件 | 相比资源设定限值，其内存使用量超过 90%时启动 |
| 解决方案 | 仍未改善时，修改部署内存限值 |
